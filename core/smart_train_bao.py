import argparse
import config
import os
import random
from smart_bao_client import Bao
from smart_util import Util


###########################################################
#  smart_train_bao.py
#
# Purpose:
#   Train bao on training queries
#
# Arguments:
#   -ds  / --dataset        dataset to run the queries on. Default: twitter
#   -d   / --dimension      dimension of the queries. Default: 3
#   -nj  / --num_join       number of join methods. Default: 1
#   -qf  / --queries_file   input file that holds the queries
#   -lf  / --labeled_file   input file that holds the labeled queries
#
# Dependencies:
#   Bao server running on the same machine
###########################################################


# https://stackoverflow.com/questions/312443/
def chunks(lst, n):
    """Yield successive n-sized chunks from lst."""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]


if __name__ == "__main__":

    # parse arguments
    parser = argparse.ArgumentParser(description="Train BAO.")
    parser.add_argument("-ds", "--dataset", help="dataset: dataset to run the queries on. Default: twitter",
                        type=str, required=False, default="twitter")
    parser.add_argument("-d", "--dimension", help="dimension of the queries. Default: 3",
                        type=int, required=False, default=3)
    parser.add_argument("-nj", "--num_join", help="num_join: number of join methods. Default: 1", 
                        required=False, type=int, default=1)
    parser.add_argument("-qf", "--queries_file", 
                        help="queries_file: input file that holds the queries", 
                        type=str, required=True)
    parser.add_argument("-lf", "--labeled_file",
                        help="labeled_file: input file that holds labeled queries",
                        type=str, required=True)
    args = parser.parse_args()

    dataset_name = args.dataset
    dimension = args.dimension
    num_of_joins = args.num_join
    queries_file = args.queries_file
    labeled_queries_file = args.labeled_file
    
    database_config = config.database_configs["postgresql"]
    dataset = config.datasets[dataset_name]

    print("start training BAO ...")

    # load queries into memory
    queries = dataset.load_queries_file(dimension, queries_file)
    # Build map <id, query>
    queries_map = {}
    for query in queries:
        queries_map[query["id"]] = query

    # load labeled queries into memory
    labeled_queries = Util.load_labeled_queries_file(dimension, labeled_queries_file, num_of_joins)
    print("loaded ", len(labeled_queries), " queries for training.")

    # break training labeled_queries into 50 random chunks 
    random.seed(42)
    query_sequence = random.choices(labeled_queries, k=len(labeled_queries))
    pg_chunks, *bao_chunks = list(chunks(query_sequence, 50))

    # start looping training queries chunks
    bao_client = Bao(
        database_config,
        dataset,
        dimension,
        num_of_joins
    )

    # loop first chunk of queries to only run on PG
    for labeled_query in pg_chunks:
        # construct sql string
        query = queries_map[labeled_query["id"]]
        sql = dataset.construct_sql_str(query, dimension)
        # collect querying time of the original query generated by PG
        pg_time = labeled_query["time_0"]
        # report reward to bao_server
        bao_client.report_reward(sql, pg_time)
        print("x", "x", labeled_query["id"], pg_time, "PG", flush=True)

    for c_idx, chunk in enumerate(bao_chunks):
        # retrain Bao
        os.system("cd ../../BaoForPostgreSQL/bao_server && python3 baoctl.py --retrain")
        os.system("sync")
        # loop every chunk of queries, use Bao to plan, then collect querying time of the plan
        for q_idx, labeled_query in enumerate(chunk):
            # construct sql string
            query = queries_map[labeled_query["id"]]
            sql = dataset.construct_sql_str(query, dimension)
            # use Bao to select the query plan
            plan_id = bao_client.plan_query(sql)
            sql = bao_client.arm_to_hint(sql, plan_id)
            # collect querying time of the query plan
            q_time = labeled_query["time_" + str(plan_id)]
            # report reward to bao_server
            bao_client.report_reward(sql, q_time)
            print(c_idx, q_idx, labeled_query["id"], q_time, flush=True)